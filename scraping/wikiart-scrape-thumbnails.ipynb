{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b88327b",
   "metadata": {},
   "source": [
    "# Wikiart Scraper\n",
    "\n",
    "#### Description\n",
    "\n",
    "The following script is designed to load the page from wikiart.org that contains all of a single artist's works. It uses selenium chrome to scroll down the page slowly in order to load all of the thumbnails. Then, it downloads all of the thumbnail images. Test first to make the page loads all the images for a single artist, then make `DO_DOWNLOAD = True` and run.\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "- `requests`\n",
    "- `beautifulsoup4`\n",
    "- `selenium` and the corresponding Firefox driver\n",
    "- `pillow`\n",
    "\n",
    "\n",
    "#### Ethical Scraping\n",
    "\n",
    "Wikiart makes its contents available under Fair Use (for more copyright information, visit wikiart.org). And since we are only downloading the image thumbnails, we feel that this does not put undue stress on their servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2276f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf3cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "\n",
    "WIKIART_URL_PREFIX = 'https://www.wikiart.org/en/'\n",
    "WIKIART_URL_SUFFIX = '/all-works#!#filterName:all-paintings-chronologically,resultType:masonry'\n",
    "N_INITIAL_IMAGES_TO_SKIP = 3\n",
    "N_SCROLLS_PER_LOAD_LENGTH = 4\n",
    "STANDARD_WAIT_TIME = 2\n",
    "Y_SCROLL_DISTANCE = 500\n",
    "N_FAILURES_BEFORE_STOP = 4\n",
    "RESIZE_DIMS = (224, 224)\n",
    "SAVE_PATH = '.'\n",
    "\n",
    "# set this to True once it seems like it's working correctly\n",
    "DO_DOWNLOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_wikiart_URL(artist_name):\n",
    "    artist_name_sani = '-'.join(artist_name.lower().split(' '))\n",
    "    return WIKIART_URL_PREFIX + artist_name_sani + WIKIART_URL_SUFFIX\n",
    "\n",
    "def construct_artist_path(artist_type, artist_name):\n",
    "    return os.path.join(artist_type, artist_name.replace(' ', '').replace('-', ''))\n",
    "\n",
    "def makedir_safe(save_dir):\n",
    "    try:\n",
    "        os.makedirs(save_dir)\n",
    "    except FileExistsError:\n",
    "        print(save_dir, 'already exists')\n",
    "\n",
    "def scroll_down_to_bottom(driver):\n",
    "    \n",
    "    def scroll_one_load_length(driver, scrollYPos):\n",
    "        for timeInd in range(0, N_SCROLLS_PER_LOAD_LENGTH):\n",
    "            time.sleep(STANDARD_WAIT_TIME)\n",
    "            driver.execute_script(\"window.scrollTo(0, \" + str(scrollYPos) + \")\")\n",
    "            scrollYPos += Y_SCROLL_DISTANCE\n",
    "        return scrollYPos\n",
    "    \n",
    "    def load_more(driver, failToLoadCount):\n",
    "        try:\n",
    "            driver.find_element_by_class_name('load-more-phrase').click()\n",
    "            return failToLoadCount\n",
    "        except ElementNotInteractableException:\n",
    "            failToLoadCount += 1\n",
    "            return failToLoadCount\n",
    "        \n",
    "    scrollYPos = Y_SCROLL_DISTANCE\n",
    "    failToLoadCount = 0\n",
    "    \n",
    "    while failToLoadCount < N_FAILURES_BEFORE_STOP:\n",
    "        scrollYPos = scroll_one_load_length(driver, scrollYPos)\n",
    "        failToLoadCount = load_more(driver, failToLoadCount)\n",
    "        print('failToLoadCount', failToLoadCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the artists and categories you would like to scrape\n",
    "\n",
    "abstractArtists = [\n",
    "    'Frank Stella',\n",
    "    'Ellsworth Kelly',\n",
    "    'Sol LeWitt',\n",
    "    'Piet Mondrian',\n",
    "    'Sophie Taeuber-Arp',\n",
    "    'Wassily Kandinsky',\n",
    "    'Paul Klee',\n",
    "    'Josef Albers',\n",
    "    'Kazimir Malevich',\n",
    "    'Hilma af Klint',\n",
    "]\n",
    "\n",
    "surrealArtists = [\n",
    "    'Yves Tanguy',\n",
    "    'Salvador Dali',\n",
    "    'Joan Miro',\n",
    "    'Rene Magritte',\n",
    "    'Max Ernst',\n",
    "    'Giorgio de Chirico',\n",
    "    'Remedios Varo',\n",
    "]\n",
    "\n",
    "artists = {\n",
    "    'abstract': abstractArtists,\n",
    "    'surreal': surrealArtists,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.maximize_window()\n",
    "\n",
    "for artistType, artistList in artists.items():\n",
    "    \n",
    "    for artistName in artistList:\n",
    "        \n",
    "        print('scraping for', artistName)\n",
    "        \n",
    "        subPath = construct_artist_path(artistType, artistName)\n",
    "        \n",
    "        saveDir = Path(os.path.join(SAVE_PATH, 'scrapedArt', subPath))\n",
    "        saveDirResize = Path(os.path.join(SAVE_PATH, 'scrapedArtResize', subPath))\n",
    "\n",
    "        makedir_safe(saveDir)\n",
    "        makedir_safe(saveDirResize)\n",
    "        \n",
    "        targetURL = construct_wikiart_URL(artistName)\n",
    "        \n",
    "        driver.get(targetURL)\n",
    "\n",
    "        status = scroll_down_to_bottom(driver)\n",
    "        \n",
    "        artist_art_page = driver.page_source\n",
    "        soup = BeautifulSoup(artist_art_page, \"html.parser\")\n",
    "        imageTags = soup.select('img')\n",
    "        imageLinks = [tag.get('src') for tag in imageTags]\n",
    "        \n",
    "        for imageURL in imageLinks[N_INITIAL_IMAGES_TO_SKIP:]:\n",
    "            \n",
    "            fileName = os.path.basename(imageURL)\n",
    "\n",
    "            savePath = saveDir/fileName\n",
    "            savePathResize = saveDirResize/fileName\n",
    "            \n",
    "            if DO_DOWNLOAD:\n",
    "                img_data = requests.get(imageURL).content\n",
    "\n",
    "                with open(savePath, 'wb') as handler:\n",
    "                    handler.write(img_data)\n",
    "\n",
    "                image = Image.open(savePath)\n",
    "                image_resized = image.resize(RESIZE_DIMS)\n",
    "                image_resized.save(savePathResize)\n",
    "            else:\n",
    "                print('we would have downloaded and resized', imageURL)\n",
    "\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
